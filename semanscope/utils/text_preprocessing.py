"""
Text preprocessing utilities for handling Chinese radicals and other problematic characters
that may cause NaN issues in embedding models.
"""
import re
import unicodedata
from typing import List, Tuple
import streamlit as st


class ChineseTextPreprocessor:
    """Preprocessor for Chinese text to handle radicals and special characters"""

    def __init__(self):
        # Common problematic Unicode ranges that may cause embedding issues
        self.problematic_ranges = [
            (0x2E80, 0x2EFF),  # CJK Radicals Supplement
            (0x2F00, 0x2FDF),  # Kangxi Radicals
            (0x2FF0, 0x2FFF),  # Ideographic Description Characters
            (0x3400, 0x4DBF),  # CJK Extension A (rare characters)
            (0x20000, 0x2A6DF), # CJK Extension B (very rare characters)
            (0x2A700, 0x2B73F), # CJK Extension C
            (0x2B740, 0x2B81F), # CJK Extension D
            (0x2B820, 0x2CEAF), # CJK Extension E
        ]

        # Safe Chinese character ranges
        self.safe_ranges = [
            (0x4E00, 0x9FFF),   # CJK Unified Ideographs (main block)
            (0x3400, 0x4DBF),   # CJK Extension A (commonly used)
        ]

        # Common safe radicals (Kangxi radicals that are typically well-supported)
        self.safe_radicals = {
            '‰∏Ä', '‰∏®', '‰∏∂', '‰∏ø', '‰πô', '‰∫Ö', '‰∫å', '‰∫†', '‰∫∫', 'ÂÑø',
            'ÂÖ•', 'ÂÖ´', 'ÂÜÇ', 'ÂÜñ', 'ÂÜ´', 'Âá†', 'Âáµ', 'ÂàÄ', 'Âäõ', 'Âãπ',
            'Âåï', 'Âåö', 'Âå∏', 'ÂçÅ', 'Âçú', 'Âç©', 'ÂéÇ', 'Âé∂', 'Âèà', 'Âè£',
            'Âõó', 'Âúü', 'Â£´', 'Â§Ç', 'Â§ä', 'Â§ï', 'Â§ß', 'Â•≥', 'Â≠ê', 'ÂÆÄ',
            'ÂØ∏', 'Â∞è', 'Â∞¢', 'Â∞∏', 'Â±Æ', 'Â±±', 'Â∑ù', 'Â∑•', 'Â∑±', 'Â∑æ',
            'Âπ≤', 'Âπ∫', 'Âπø', 'Âª¥', 'Âªæ', 'Âºã', 'Âºì', 'ÂΩê', 'ÂΩ°', 'ÂΩ≥',
            'ÂøÉ', 'Êàà', 'Êà∂', 'Êâã', 'ÊîØ', 'Êî¥', 'Êñá', 'Êñó', 'Êñ§', 'Êñπ',
            'Êó†', 'Êó•', 'Êõ∞', 'Êúà', 'Êú®', 'Ê¨†', 'Ê≠¢', 'Ê≠π', 'ÊÆ≥', 'ÊØã',
            'ÊØî', 'ÊØõ', 'Ê∞è', 'Ê∞î', 'Ê∞¥', 'ÁÅ´', 'Áà™', 'Áà∂', 'Áàª', 'Áàø',
            'Áâá', 'Áâô', 'Áâõ', 'Áä¨', 'ÁéÑ', 'Áéâ', 'Áìú', 'Áì¶', 'Áîò', 'Áîü',
            'Áî®', 'Áî∞', 'Áñã', 'Áñí', 'Áô∂', 'ÁôΩ', 'ÁöÆ', 'Áöø', 'ÁõÆ', 'Áüõ',
            'Áü¢', 'Áü≥', 'Á§∫', 'Á¶∏', 'Á¶æ', 'Á©¥', 'Á´ã', 'Á´π', 'Á±≥', 'Á≥∏',
            'Áº∂', 'ÁΩë', 'Áæä', 'ÁæΩ', 'ËÄÅ', 'ËÄå', 'ËÄí', 'ËÄ≥', 'ËÅø', 'ËÇâ',
            'Ëá£', 'Ëá™', 'Ëá≥', 'Ëáº', 'Ëàå', 'Ëàõ', 'Ëàü', 'ËâÆ', 'Ëâ≤', 'Ëâ∏',
            'Ëôç', 'Ëô´', 'Ë°Ä', 'Ë°å', 'Ë°£', 'Ë•æ', 'Ë¶ã', 'Ëßí', 'Ë®Ä', 'Ë∞∑',
            'Ë±Ü', 'Ë±ï', 'Ë±∏', 'Ë≤ù', 'Ëµ§', 'Ëµ∞', 'Ë∂≥', 'Ë∫´', 'Ëªä', 'Ëæõ',
            'Ëæ∞', 'Ëæµ', 'ÈÇë', 'ÈÖâ', 'ÈáÜ', 'Èáå', 'Èáë', 'Èï∑', 'ÈñÄ', 'Èòú',
            'Èö∂', 'Èöπ', 'Èõ®', 'Èùí', 'Èùû', 'Èù¢', 'Èù©', 'Èüã', 'Èü≠', 'Èü≥',
            'È†Å', 'È¢®', 'È£õ', 'È£ü', 'È¶ñ', 'È¶ô', 'È¶¨', 'È™®', 'È´ò', 'È´ü',
            'È¨•', 'È¨Ø', 'È¨≤', 'È¨º', 'È≠ö', 'È≥•', 'Èπµ', 'Èπø', 'È∫•', 'È∫ª',
            'ÈªÉ', 'Èªç', 'Èªë', 'Èªπ', 'ÈªΩ', 'Èºé', 'Èºì', 'Èº†', 'Èºª', 'ÈΩä',
            'ÈΩí', 'Èæç', 'Èæú', 'Èæ†'
        }

    def is_problematic_character(self, char: str) -> bool:
        """Check if a character is in a problematic Unicode range"""
        code = ord(char)

        # Check against problematic ranges
        for start, end in self.problematic_ranges:
            if start <= code <= end:
                # Exception: if it's a commonly safe radical, allow it
                if char in self.safe_radicals:
                    return False
                return True

        return False

    def is_safe_chinese_character(self, char: str) -> bool:
        """Check if a character is in a safe Chinese character range"""
        code = ord(char)

        # Check against safe ranges
        for start, end in self.safe_ranges:
            if start <= code <= end:
                return True

        # Also allow safe radicals
        if char in self.safe_radicals:
            return True

        return False

    def preprocess_text_list(self, texts: List[str], warn_on_changes: bool = True) -> Tuple[List[str], List[str]]:
        """
        Preprocess a list of texts to handle problematic characters

        Returns:
            tuple: (processed_texts, warnings)
        """
        processed_texts = []
        warnings = []

        for i, text in enumerate(texts):
            processed_text, text_warnings = self.preprocess_single_text(text, warn_on_changes)
            processed_texts.append(processed_text)

            if text_warnings:
                warnings.extend([f"Text {i+1}: {w}" for w in text_warnings])

        return processed_texts, warnings

    def preprocess_single_text(self, text: str, warn_on_changes: bool = True) -> Tuple[str, List[str]]:
        """
        Preprocess a single text to handle problematic characters

        Returns:
            tuple: (processed_text, warnings)
        """
        if not text or not text.strip():
            return text, []

        original_text = text
        warnings = []

        # Remove or replace problematic characters
        processed_chars = []
        removed_chars = set()

        for char in text:
            if self.is_problematic_character(char):
                # Try to find a replacement or skip
                replacement = self._get_character_replacement(char)
                if replacement:
                    processed_chars.append(replacement)
                    if char not in removed_chars:
                        removed_chars.add(char)
                else:
                    # Skip problematic character
                    if char not in removed_chars:
                        removed_chars.add(char)
            else:
                processed_chars.append(char)

        processed_text = ''.join(processed_chars)

        # Generate warnings
        if removed_chars and warn_on_changes:
            removed_list = list(removed_chars)
            warnings.append(f"Removed/replaced problematic characters: {', '.join(removed_list)}")

        # Check if text became empty or too short
        if len(processed_text.strip()) == 0 and len(original_text.strip()) > 0:
            # warnings.append("Text became empty after preprocessing")
            processed_text = "‚ñ°"  # Use a safe placeholder
        elif len(processed_text.strip()) < len(original_text.strip()) * 0.5:
            warnings.append(f"Text significantly shortened: '{original_text[:20]}...' ‚Üí '{processed_text[:20]}...'")

        return processed_text, warnings

    def _get_character_replacement(self, char: str) -> str:
        """Get a replacement for a problematic character"""
        # Common radical replacements
        radical_replacements = {
            # Ideographic Description Characters -> safe alternatives
            '‚ø∞': '',  # Left-right composition
            '‚ø±': '',  # Top-bottom composition
            '‚ø≤': '',  # Left-middle-right composition
            '‚ø≥': '',  # Top-middle-bottom composition
            '‚ø¥': '',  # Surround composition
            '‚øµ': '',  # Surround from above
            '‚ø∂': '',  # Surround from below
            '‚ø∑': '',  # Surround from left
            '‚ø∏': '',  # Surround from upper left
            '‚øπ': '',  # Surround from upper right
            '‚ø∫': '',  # Surround from lower left
            '‚øª': '',  # Overlaid composition
        }

        return radical_replacements.get(char, '')

    def analyze_text_list(self, texts: List[str]) -> dict:
        """Analyze a list of texts for potential issues"""
        analysis = {
            'total_texts': len(texts),
            'problematic_texts': 0,
            'problematic_characters': set(),
            'empty_texts': 0,
            'very_short_texts': 0,
            'recommendations': []
        }

        for text in texts:
            if not text or not text.strip():
                analysis['empty_texts'] += 1
                continue

            if len(text.strip()) <= 1:
                analysis['very_short_texts'] += 1

            has_problematic = False
            for char in text:
                if self.is_problematic_character(char):
                    analysis['problematic_characters'].add(char)
                    has_problematic = True

            if has_problematic:
                analysis['problematic_texts'] += 1

        # Generate recommendations
        if analysis['problematic_texts'] > 0:
            analysis['recommendations'].append(
                f"‚ö†Ô∏è {analysis['problematic_texts']} texts contain potentially problematic characters"
            )

        if analysis['empty_texts'] > 0:
            analysis['recommendations'].append(
                f"‚ùå {analysis['empty_texts']} texts are empty or whitespace-only"
            )

        if analysis['very_short_texts'] > 0:
            analysis['recommendations'].append(
                f"‚ö†Ô∏è {analysis['very_short_texts']} texts are very short (‚â§1 character)"
            )

        if len(analysis['problematic_characters']) > 0:
            char_list = ', '.join(sorted(analysis['problematic_characters']))[:100]
            if len(char_list) == 100:
                char_list += "..."
            analysis['recommendations'].append(
                f"üîç Problematic characters found: {char_list}"
            )

        return analysis


def preprocess_texts_for_embedding(texts: List[str], show_warnings: bool = True) -> List[str]:
    """
    Convenience function to preprocess texts before embedding generation

    Args:
        texts: List of input texts
        show_warnings: Whether to show preprocessing warnings in Streamlit

    Returns:
        List of preprocessed texts
    """
    preprocessor = ChineseTextPreprocessor()

    # Analyze texts first
    analysis = preprocessor.analyze_text_list(texts)

    if show_warnings and analysis['recommendations']:
        with st.expander("üîç Text Preprocessing Analysis", expanded=False):
            st.markdown("**Potential Issues Detected:**")
            for rec in analysis['recommendations']:
                st.markdown(f"- {rec}")

    # Preprocess texts
    processed_texts, warnings = preprocessor.preprocess_text_list(texts, warn_on_changes=show_warnings)

    if show_warnings and warnings:
        with st.expander("üîß Text Preprocessing Changes", expanded=False):
            st.markdown("**Characters Modified/Removed:**")
            for warning in warnings:  
                st.markdown(f"- {warning}")

    return processed_texts